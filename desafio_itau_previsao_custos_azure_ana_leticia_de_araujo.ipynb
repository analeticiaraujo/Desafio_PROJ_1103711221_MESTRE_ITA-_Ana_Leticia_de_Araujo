{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7517dfdb",
   "metadata": {},
   "source": [
    "# Desafio Técnico Itaú/CNpq - Previsão de Custos de VMs na Azure (Versão Refatorada)\n",
    "*Autora: Ana Leticia de Araujo*\n",
    "\n",
    "Este notebook implementa um pipeline de dados e Machine Learning para prever os custos de Máquinas Virtuais da Azure. O código foi refatorado seguindo princípios de Clean Code para garantir modularidade, legibilidade e fácil manutenção, ao mesmo tempo em que preserva a estrutura narrativa e explicativa de um notebook.\n",
    "\n",
    "**A estrutura do notebook é a seguinte:**\n",
    "1.  **Configuração Centralizada:** Todos os parâmetros e constantes do projeto são definidos em um único lugar.\n",
    "2.  **Definição das Funções do Pipeline:** Todas as funções que executam as tarefas (coleta, limpeza, treinamento, etc.) são definidas em uma única \"célula de ferramentas\".\n",
    "3.  **Execução do Pipeline Passo a Passo:** As funções são chamadas em sequência, célula a célula, para executar o pipeline, permitindo a inspeção dos resultados em cada etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ETAPA 0: IMPORTAÇÃO DE BIBLIOTECAS ---\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acb6ef",
   "metadata": {},
   "source": [
    "## 1. Configuração Centralizada do Pipeline\n",
    "Nesta célula, todas as configurações, como URLs, nomes de arquivos e parâmetros do modelo, são definidas para fácil manutenção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c99fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centraliza todas as configurações e \"strings mágicas\" em um único lugar\n",
    "CONFIG = {\n",
    "    \"api_url\": \"https://prices.azure.com/api/retail/prices?$filter=serviceName eq 'Virtual Machines' and (armRegionName eq 'brazilsoutheast' or armRegionName eq 'eastus') and priceType eq 'Consumption'\",\n",
    "    \"columns_to_select\": ['armSkuName', 'retailPrice', 'armRegionName', 'vcpu', 'memoria_gb'],\n",
    "    \"column_rename_map\": {\n",
    "        'armSkuName': 'tipo_instancia',\n",
    "        'retailPrice': 'preco_hora',\n",
    "        'armRegionName': 'regiao'\n",
    "    },\n",
    "    \"region_translation_map\": {\n",
    "        'eastus': 'Leste dos EUA',\n",
    "        'brazilsoutheast': 'Sudeste do Brasil'\n",
    "    },\n",
    "    \"exploratory_plot_path\": \"analise_exploratoria_vcpu_por_regiao.png\",\n",
    "    \"dashboard_plot_path\": \"dashboard_performance_modelo.png\",\n",
    "    \"results_csv_path\": \"dados_tratados_e_resultados.csv\",\n",
    "    \"random_state\": 42,\n",
    "    \"test_size\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411a46f",
   "metadata": {},
   "source": [
    "## 2. Definição das Funções do Pipeline\n",
    "Aqui definimos todas as funções que servirão como os blocos de construção do nosso pipeline. Cada função tem uma única responsabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a0004",
   "metadata": {},
   "source": [
    "### 2.1 Funções de Coleta e Processamento de Dados\n",
    "Iniciamos com as funções que formam o núcleo do nosso pipeline de ETL (Extração, Transformação e Carga). A primeira é responsável pela **extração** dos dados brutos da API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ff4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_from_api(api_url: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Busca e pagina os dados da API da Azure, retornando um DataFrame.\"\"\"\n",
    "    print(\"--- Coletando dados da API... ---\")\n",
    "    all_items = []\n",
    "    page_number = 1\n",
    "    \n",
    "    while api_url:\n",
    "        print(f\"Buscando dados da página {page_number}...\")\n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            all_items.extend(data.get('Items', []))\n",
    "            api_url = data.get('NextPageLink')\n",
    "            page_number += 1\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erro ao acessar a API: {e}\")\n",
    "            return None\n",
    "            \n",
    "    if not all_items:\n",
    "        print(\"Nenhum dado foi retornado pela API.\")\n",
    "        return None\n",
    "            \n",
    "    print(f\"SUCESSO: {len(all_items)} registros de preços coletados.\")\n",
    "    return pd.DataFrame(all_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe42ff",
   "metadata": {},
   "source": [
    "---\n",
    "A seguir, definimos uma função auxiliar (`helper function`) crucial para a etapa de **transformação**. Esta função atuará como um \"decodificador\" para extrair a contagem de vCPUs e a quantidade de memória a partir do nome técnico da instância (`armSkuName`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specs_from_name(sku_name: str) -> Tuple[Optional[int], Optional[float]]:\n",
    "    \"\"\"Extrai vCPU e Memória do nome da instância (armSkuName).\"\"\"\n",
    "    memory_ratio_map = {'B': 2, 'D': 4, 'E': 8, 'F': 2, 'M': 8, 'DC': 4}\n",
    "    match = re.search(r'Standard_([A-Z]+)(\\d+)', sku_name)\n",
    "    if not match: return None, None\n",
    "    family, vcpu = match.group(1), int(match.group(2))\n",
    "    ratio = memory_ratio_map.get(family, 4)\n",
    "    memory = float(vcpu * ratio)\n",
    "    return vcpu, memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e7414",
   "metadata": {},
   "source": [
    "---\n",
    "Com a função auxiliar pronta, construímos a principal função de limpeza e engenharia de features. Ela orquestrará todo o processo de **transformação**: aplicará filtros, usará a `get_specs_from_name` para criar novas colunas e preparará o DataFrame final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_feature_engineer(df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Aplica a limpeza, engenharia de features e transformações no DataFrame.\"\"\"\n",
    "    print(\"\\n--- Limpando dados e aplicando engenharia de features... ---\")\n",
    "    query_filter = (\n",
    "        (df['unitOfMeasure'] == '1 Hour') &\n",
    "        (df['armSkuName'].str.contains('Standard_D|Standard_B|Standard_E', na=False)) &\n",
    "        (~df['meterName'].str.contains('Spot', na=False)) &\n",
    "        (~df['meterName'].str.contains('Low Priority', na=False)) &\n",
    "        (~df['productName'].str.contains('Promo', na=False))\n",
    "    )\n",
    "    df_clean = df[query_filter].copy()\n",
    "\n",
    "    specs_df = df_clean['armSkuName'].apply(get_specs_from_name).apply(pd.Series)\n",
    "    df_clean['vcpu'], df_clean['memoria_gb'] = specs_df[0], specs_df[1]\n",
    "\n",
    "    df_final = df_clean[CONFIG[\"columns_to_select\"]].rename(columns=CONFIG[\"column_rename_map\"]).dropna().copy()\n",
    "    \n",
    "    if df_final.empty: return None\n",
    "        \n",
    "    df_final['regiao'] = df_final['regiao'].map(CONFIG[\"region_translation_map\"])\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e91ab7",
   "metadata": {},
   "source": [
    "### 2.2 Funções de Visualização, Modelagem e Resultados\n",
    "Agora definimos as funções para as etapas restantes: Análise Exploratória, Modelagem, Avaliação e Salvamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exploratory_plot(df: pd.DataFrame):\n",
    "    \"\"\"Gera e salva o gráfico de análise exploratória.\"\"\"\n",
    "    print(\"\\n--- Gerando análise exploratória visual... ---\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    g = sns.lmplot(data=df, x='vcpu', y='preco_hora', hue='regiao', x_estimator=np.mean, height=7, aspect=1.5, palette='viridis')\n",
    "    g.fig.suptitle('Tendência de Custo Médio por Quantidade de vCPUs', fontsize=18, y=1.03, weight='bold')\n",
    "    g.set_axis_labels('Quantidade de vCPUs', 'Custo Médio por Hora (USD)', fontsize=14)\n",
    "    g.legend.set_title(\"Região\")\n",
    "    plt.savefig(CONFIG[\"exploratory_plot_path\"], dpi=300)\n",
    "    print(f\"Gráfico exploratório salvo em: {CONFIG['exploratory_plot_path']}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a4c19",
   "metadata": {},
   "source": [
    "---\n",
    "A função seguinte encapsula toda a lógica de **treinamento do modelo** de regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df: pd.DataFrame) -> Tuple[object, pd.DataFrame, pd.Series, np.ndarray]:\n",
    "    \"\"\"Prepara os dados, treina o modelo e retorna os resultados.\"\"\"\n",
    "    print(\"\\n--- Preparando dados e treinando o modelo... ---\")\n",
    "    df_processed = pd.get_dummies(df, columns=['regiao'], prefix='reg')\n",
    "    df_processed.drop('tipo_instancia', axis=1, inplace=True)\n",
    "    \n",
    "    X = df_processed.drop('preco_hora', axis=1)\n",
    "    y = df_processed['preco_hora']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=CONFIG[\"test_size\"], random_state=CONFIG[\"random_state\"])\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=CONFIG[\"random_state\"])\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Modelo treinado com sucesso!\")\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    return model, X_test, y_test, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f064b",
   "metadata": {},
   "source": [
    "---\n",
    "Esta função é responsável por **avaliar a performance** do modelo treinado e gerar o dashboard visual com os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9bff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot(y_test: pd.Series, predictions: np.ndarray, df_final: pd.DataFrame, X_test: pd.DataFrame):\n",
    "    \"\"\"Calcula métricas, gera e salva o dashboard de performance.\"\"\"\n",
    "    print(\"\\n--- Avaliando performance e gerando dashboard... ---\")\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(f\"Erro Quadrático Médio (MSE): {mse:.4f}\")\n",
    "    print(f\"Coeficiente de Determinação (R²): {r2:.4f}\")\n",
    "\n",
    "    plot_data = X_test.copy()\n",
    "    plot_data.loc[:, 'preco_real'] = y_test\n",
    "    plot_data.loc[:, 'preco_previsto'] = predictions\n",
    "    plot_data.loc[:, 'residuos'] = y_test - predictions\n",
    "    plot_data.loc[:, 'regiao'] = df_final.loc[X_test.index, 'regiao']\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-talk')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14))\n",
    "    fig.suptitle('Dashboard de Performance do Modelo de Regressão', fontsize=22, weight='bold', y=1.02)\n",
    "    \n",
    "    sns.scatterplot(data=plot_data, x='preco_real', y='preco_previsto', hue='regiao', palette='viridis', alpha=0.8, s=100, ax=ax1)\n",
    "    ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red', linewidth=2, label='Previsão de custo ideal')\n",
    "    ax1.set_title('Gráfico de Dispersão: Preço Real vs. Previsão', fontsize=16)\n",
    "    ax1.legend(title='Região')\n",
    "    ax1.text(0.05, 0.95, f'$R^2 = {r2:.4f}$\\nMSE = {mse:.5f}', transform=ax1.transAxes, fontsize=14, verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', fc='lightgray', alpha=0.6))\n",
    "\n",
    "    sns.scatterplot(data=plot_data, x='preco_previsto', y='residuos', hue='regiao', palette='viridis', alpha=0.7, s=100, legend=False, ax=ax2)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--')\n",
    "    ax2.set_title('Gráfico de Resíduos (Análise de Erros)', fontsize=16)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(CONFIG[\"dashboard_plot_path\"], dpi=300)\n",
    "    print(f\"Dashboard salvo em: {CONFIG['dashboard_plot_path']}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae60a9d",
   "metadata": {},
   "source": [
    "---\n",
    "Finalmente, uma função para **salvar os resultados** numéricos em um arquivo `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f79bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(X_test: pd.DataFrame, y_test: pd.Series, predictions: np.ndarray, df_final: pd.DataFrame):\n",
    "    \"\"\"Salva os resultados finais em um arquivo CSV.\"\"\"\n",
    "    print(\"\\n--- Salvando resultados em CSV... ---\")\n",
    "    df_resultados = X_test.copy()\n",
    "    df_resultados['preco_real'] = y_test\n",
    "    df_resultados['preco_previsto'] = predictions\n",
    "    df_resultados['regiao'] = df_final.loc[X_test.index, 'regiao']\n",
    "    df_resultados.to_csv(CONFIG[\"results_csv_path\"], index=False)\n",
    "    print(f\"Arquivo de resultados salvo em: {CONFIG['results_csv_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e5c38",
   "metadata": {},
   "source": [
    "## 3. Execução do Pipeline Passo a Passo\n",
    "As células a seguir orquestram a execução do pipeline, chamando as funções definidas acima e permitindo a visualização dos resultados de cada etapa principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf0b57",
   "metadata": {},
   "source": [
    "### ETAPA 1: Coleta de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função para buscar os dados da API\n",
    "df_raw = fetch_data_from_api(CONFIG[\"api_url\"])\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame bruto, se a coleta for bem-sucedida\n",
    "if df_raw is not None:\n",
    "    display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb324",
   "metadata": {},
   "source": [
    "### ETAPA 2: Limpeza e Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ef632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função para limpar os dados e criar novas features\n",
    "if df_raw is not None:\n",
    "    df_final = clean_and_feature_engineer(df_raw)\n",
    "    if df_final is not None:\n",
    "        display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e9f69",
   "metadata": {},
   "source": [
    "### ETAPA 2.5: Análise Exploratória Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7207f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o gráfico para explorar a relação entre vCPU e preço\n",
    "if df_final is not None:\n",
    "    generate_exploratory_plot(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4decca7",
   "metadata": {},
   "source": [
    "### ETAPAS 3 e 4: Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o modelo e obtém as previsões e dados de teste\n",
    "if df_final is not None:\n",
    "    model, X_test, y_test, predictions = train_model(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257ff90",
   "metadata": {},
   "source": [
    "### ETAPA 5: Avaliação e Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o dashboard de performance com os resultados do modelo\n",
    "if 'model' in locals():\n",
    "    evaluate_and_plot(y_test, predictions, df_final, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a1894",
   "metadata": {},
   "source": [
    "### ETAPA 6: Geração do Arquivo de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o CSV final com os resultados\n",
    "if 'model' in locals():\n",
    "    save_results(X_test, y_test, predictions, df_final)\n",
    "    print(\"\\n--- DESAFIO CONCLUÍDO ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
