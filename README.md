<h1><strong>Desafio T√©cnico - Ita√∫/CNpq - Trilha de Dados & IA</strong></h1>

<hr>

<h2>üí° Vis√£o Geral do Projeto</h2>
<p>Este projeto implementa um prot√≥tipo de um m√≥dulo de an√°lise de custos para a nuvem <strong>Microsoft Azure</strong>, conforme proposto no desafio. O objetivo principal √© criar um pipeline de dados robusto que coleta informa√ß√µes de pre√ßos em tempo real de uma API oficial e utiliza um modelo de Machine Learning para prever os custos de inst√¢ncias computacionais com alta precis√£o.</p>

<hr>

<h2>üõ†Ô∏è Metodologia</h2>
<p>O pipeline foi constru√≠do seguindo as melhores pr√°ticas de engenharia de dados e ci√™ncia de dados, dividido nas seguintes etapas:</p>
<ul>
<li><strong>‚òÅÔ∏è Coleta de Dados via API Oficial</strong>: Os dados de pre√ßos foram consumidos diretamente da API oficial <strong>Azure Retail Prices</strong>. O pipeline foi projetado para lidar com a pagina√ß√£o da API, coletando de forma automatizada todos os registos de pre√ßos <em>On-Demand</em> para M√°quinas Virtuais em duas regi√µes distintas: <strong>Sudeste do Brasil (<code>brazilsoutheast</code>)</strong> e <strong>Leste dos EUA (<code>eastus</code>)</strong>. A an√°lise foi adaptada para incluir dados de VMs com sistemas operativos Linux e Windows, refletindo a disponibilidade real de produtos na API para as regi√µes consultadas.</li>
<li><strong>‚ú® Engenharia de Features e Processamento</strong>: Ap√≥s a coleta, os dados passaram por um rigoroso processo de tratamento:
<ul>
<li>Limpeza e filtragem para remover modelos de pre√ßos vol√°teis (como <em>Spot</em>) e focar em inst√¢ncias de uso geral.</li>
<li>Extra√ß√£o program√°tica das especifica√ß√µes (vCPU e Mem√≥ria) diretamente do nome da inst√¢ncia (<code>armSkuName</code>) utilizando express√µes regulares e um mapeamento inteligente de fam√≠lias.</li>
<li>A <em>feature</em> categ√≥rica <code>regiao</code> foi transformada em colunas num√©ricas atrav√©s de <em>One-Hot Encoding</em> para ser utilizada pelo modelo.</li>
</ul>
</li>
<li><strong>üß† Treinamento do Modelo de IA</strong>: Foi treinado um modelo de Regress√£o (<code>RandomForestRegressor</code>) para prever a coluna <code>preco_hora</code> com base nas caracter√≠sticas extra√≠das (vCPU, Mem√≥ria) e na localiza√ß√£o da inst√¢ncia.</li>
<li><strong>üìä Avalia√ß√£o e Visualiza√ß√£o</strong>: O modelo alcan√ßou uma alt√≠ssima precis√£o, com um <strong>R¬≤ (Coeficiente de Determina√ß√£o) superior a 0.99</strong>. Os resultados s√£o apresentados num dashboard de performance (<code>dashboard_performance_modelo.png</code>), que inclui a an√°lise de precis√£o (Real vs. Previsto) e um gr√°fico de res√≠duos para validar a aus√™ncia de vi√©s no modelo.</li>
</ul>

<hr>

<h2>‚ñ∂Ô∏è Como Executar</h2>
<p>Existem dois m√©todos para executar este projeto.</p>

<h3><strong>M√©todo 1: Ambiente Virtual Python (Execu√ß√£o Local)</strong></h3>
<p><em>Este m√©todo √© ideal para desenvolvimento e an√°lise interativa no Jupyter Notebook.</em></p>

<h4><strong>Pr√©-requisitos</strong></h4>
<ul>
<li>Python 3.12+</li>
<li>Git</li>
</ul>

<h4><strong>Passo a Passo</strong></h4>
<ol>
<li><strong>Clone o reposit√≥rio</strong>:
<pre><code>git clone &lt;URL_DO_SEU_REPOSITORIO&gt;
cd &lt;NOME_DO_REPOSITORIO&gt;</code></pre>
</li>
<li><strong>Crie e ative um ambiente virtual</strong>:
<pre><code># Cria o ambiente virtual
python -m venv venv

Ativa o ambiente (Windows)
.\venv\Scripts\activate

Ativa o ambiente (Linux/macOS)
source venv/bin/activate</code></pre>

</li>
<li><strong>Instale as depend√™ncias</strong>:
<p>As bibliotecas necess√°rias est√£o listadas no ficheiro <code>requirements.txt</code>. Para instalar todas, execute:</p>
<pre><code>pip install -r requirements.txt</code></pre>
</li>
<li><strong>Execute o Notebook</strong>:
<p>Abra e execute as c√©lulas do notebook <code>desafio_itau_previsao_custos_azure_ana_leticia_de_araujo.ipynb</code> num ambiente Jupyter.</p>
</li>
</ol>

<h3><strong>M√©todo 2: Usando Docker (Reprodutibilidade Garantida)</strong></h3>
<p><em>Este m√©todo utiliza o Docker para executar o pipeline num ambiente contido e 100% consistente, ideal para automa√ß√£o e para garantir que o script rode da mesma forma em qualquer m√°quina.</em></p>

<h4><strong>Pr√©-requisitos</strong></h4>
<ul>
<li>Docker instalado e em execu√ß√£o.</li>
</ul>

<h4><strong>Passo a Passo</strong></h4>
<ol>
<li><strong>Construa a Imagem Docker</strong>:
<p>No terminal, na raiz do projeto, execute o comando para construir a imagem:</p>
<pre><code>docker build -t desafio-itau-previsao .</code></pre>
</li>
<li><strong>Execute o Pipeline dentro do Cont√™iner</strong>:
<p>Ap√≥s a constru√ß√£o da imagem, execute o script <code>desafio_itau.py</code>:</p>
<pre><code>docker run --rm desafio-itau-previsao</code></pre>
<blockquote><strong>Nota Importante:</strong> Este comando iniciar√° o cont√™iner, executar√° o pipeline completo e, no final, remover√° o cont√™iner. Os ficheiros de resultado (.csv e .png) ser√£o gerados dentro do cont√™iner e descartados no final.</blockquote>
</li>
</ol>

<hr>

<h2>üìÇ Estrutura do Projeto</h2>
<ul>
<li><code>desafio_itau_previsao_custos_azure_ana_leticia_de_araujo.ipynb</code>: Notebook com a an√°lise explorat√≥ria e explicativa.</li>
<li><code>desafio_itau.py</code>: Script Python automatizado para execu√ß√£o do pipeline completo.</li>
<li><code>Dockerfile</code>: Define o ambiente de execu√ß√£o contido e reprodut√≠vel.</li>
<li><code>requirements.txt</code>: Lista as depend√™ncias do projeto.</li>
<li><code>.gitignore</code> e <code>.gitattributes</code>: Ficheiros de configura√ß√£o do Git para boas pr√°ticas de versionamento.</li>
</ul>